{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; background-color: #ef7d22; text-align: center\">\n",
    "<br><br>\n",
    "\n",
    "<h1 style=\"color: white; font-weight: bold;\">\n",
    "    PostgreSQL Data Definition Language\n",
    "</h1>\n",
    "\n",
    "<br><br> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various RDBMSs implement languages close to official SQL specifications, but rarely either a strict superset nor a strict subset of actual specs.  It is complicated further by the fact that SQL specs include SQL-86, SQL-89, SQL-92, SQL:1999, SQL:2003, SQL:2006, SQL:2008, SQL:2011, and SQL:2016.  Each of these are different, not only by adding features but also sometimes deprecating them or changing spelling.\n",
    "\n",
    "In other words, while most data definition commands you will use in PostgreSQL are mostly similar to the equivalent commands in other RDBMSs, the equivalence is not precise.  PostgreSQL supports a large number of data definition commands (all SQL-like); this lesson will highlight some particularly commonly used ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE, DROP, ALTER\n",
    "![orange-divider](https://user-images.githubusercontent.com/7065401/98619088-44ab6000-22e1-11eb-8f6d-5532e68ab274.png)\n",
    "\n",
    "The basic verbs for working with *data* in PostgreSQL are SELECT, INSERT, UPDATE, DELETE, and perhaps TRUNCATE.  The first of those does not actually change data, just retrieve it.  But the verbs of the PostgreSQL data definitions language (DDL) are CREATE, DROP, and ALTER.  GRANT is borderline, but possibly worth including as DDL.  These affect the *shape* of data rather than the content as such; however, many changes to shape by implication change underlying data globally (such as by removing it, or by changing its data type)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each regular DDL verb is followed by a noun, and usually by some additional qualifiers.  For example, we can DROP the following objects:\n",
    "\n",
    "|     Objects   |  Objects      |  Objects\n",
    "|:--------------|:--------------|:--------------\n",
    "| ACCESS METHOD | AGGREGATE     | CAST\n",
    "| COLLATION     | CONVERSION    | DATABASE\n",
    "| DOMAIN        | EVENT TRIGGER | EXTENSION\n",
    "| FOREIGN TABLE | FUNCTION      | GROUP\n",
    "| INDEX         | LANGUAGE      | MATERIALIZED VIEW\n",
    "| OPERATOR      | OPERATOR CLASS| OPERATOR FAMILY\n",
    "| OWNED         | POLICY        | PROCEDURE\n",
    "| PUBLICATION   | ROLE          | ROUTINE\n",
    "| RULE          | SCHEMA        | SEQUENCE\n",
    "| SERVER        | STATISTICS    | SUBSCRIPTION\n",
    "| TABLE         | TABLESPACE    | TEXT SEARCH CONFIGURATION\n",
    "| TEXT SEARCH DICTIONARY | TEXT SEARCH PARSER | TEXT SEARCH TEMPLATE\n",
    "| TRANSFORM     | TRIGGER       | TYPE\n",
    "| USER          | USER MAPPING  | VIEW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of those same things can be CREATE'd or ALTER'd.  All of these are useful, of course, but USER/ROLE, TABLE, DATABASE, and INDEX are those you will use during typical database configuration.\n",
    "\n",
    "Although the steps in this lesson are ones you would typically perform in an administration interface, let us work within the notebook, and using a `psycopg2` connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "user = 'ine_student'\n",
    "pwd = 'ine-password'\n",
    "host = 'localhost'\n",
    "port = '5432'\n",
    "db = 'ine'\n",
    "\n",
    "conn = psycopg2.connect(database=db, host=host, user=user, password=pwd, port=port)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactoring tables\n",
    "![orange-divider](https://user-images.githubusercontent.com/7065401/98619088-44ab6000-22e1-11eb-8f6d-5532e68ab274.png)\n",
    "\n",
    "Let us recall the definition of the `census_zipcode_geography` table.  It has some flaws we can improve.  We might define a simple function to view table definitions from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_schema(table_name, table_schema=None, conn=conn):\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        if table_schema is None:\n",
    "            sql = \"\"\"\n",
    "            SELECT column_name, data_type, character_maximum_length, \n",
    "                   column_default, is_nullable\n",
    "            FROM INFORMATION_SCHEMA.COLUMNS WHERE table_name = %(name)s;\n",
    "            \"\"\"\n",
    "        else:\n",
    "            sql = \"\"\"\n",
    "            SELECT column_name, data_type, character_maximum_length, \n",
    "                   column_default, is_nullable\n",
    "            FROM INFORMATION_SCHEMA.COLUMNS \n",
    "            WHERE table_name = %(name)s AND table_schema = %(schema)s;\n",
    "            \"\"\"\n",
    "        cur.execute(sql, {'name': table_name, 'schema': table_schema})\n",
    "        return cur.fetchall()\n",
    "    except Exception as err:\n",
    "        print(\"Problem encountered:\", err)\n",
    "        conn.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewing the table, we can see significant redundancy.  `awater` and `aland` express the same quantity as `awater_sqmi` and `aland_sqmi`, respectively, only in different units (square meters versus square miles).  Moreover, `location` is simply a combination of `intptlat` and `intptlong`.  Not only does this waste storage space, it could potentially lead to inconsistencies in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('usps', 'character', 5, None, 'NO'),\n",
       " ('aland', 'bigint', None, None, 'YES'),\n",
       " ('awater', 'bigint', None, None, 'YES'),\n",
       " ('aland_sqmi', 'numeric', None, None, 'YES'),\n",
       " ('awater_sqmi', 'numeric', None, None, 'YES'),\n",
       " ('intptlat', 'real', None, None, 'YES'),\n",
       " ('intptlong', 'real', None, None, 'YES'),\n",
       " ('location', 'point', None, None, 'YES')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_schema('census_zipcode_geography')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema namespaces\n",
    "![orange-divider](https://user-images.githubusercontent.com/7065401/98619088-44ab6000-22e1-11eb-8f6d-5532e68ab274.png)\n",
    "\n",
    "Another problem suggests itself also.  In the names of some tables, we used an implicit namespace by separating components with underscores.  PostgreSQL offers us a canonical way to do this instead, with actual namespacing and isolation.  \n",
    "\n",
    "For example, we might create both a table `home.users` and a table `business.users` that would vary not only in have distinct names, but also would have different functions, stored user FUNCTIONs, stored PROCEDUREs, OPERATORs, and other things pertaining to that namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping normally rare, only for the lesson\n",
    "try:\n",
    "    cur.execute('DROP SCHEMA census CASCADE;')\n",
    "except Exception as err:\n",
    "    conn.rollback()\n",
    "    print(\"Rolling back:\", repr(err), sep='\\n')\n",
    "else:\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute('CREATE SCHEMA census;')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table `census_zipcode_fields` has a simple design we need not improve.  Let us copy it in the new namespace (potentially we will eventually delete the tables with suboptimal design)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute('CREATE TABLE census.zipcode_fields AS TABLE census_zipcode_fields;')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('USPS', 'United States Postal Service State Abbreviation'),\n",
       " ('GEOID',\n",
       "  'Geographic Identifier - fully concatenated geographic code (State FIPS and district number)'),\n",
       " ('ALAND',\n",
       "  'Land Area (square meters) - Created for statistical purposes only')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute('SELECT * FROM census.zipcode_fields')\n",
    "cur.fetchmany(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, perhaps we should namespace the `users`, but here we want to modify the table somewhat as well to accomodate a zipcode field.  Zipcodes should exist in foreign table describing them. Let us first create that reference table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"CREATE TABLE census.zipcodes (zipcode CHAR(5) PRIMARY KEY);\")\n",
    "zips = \"INSERT INTO census.zipcodes SELECT usps FROM census_zipcode_geography;\"\n",
    "cur.execute(zips)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the schema and table for business users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"DROP SCHEMA IF EXISTS business CASCADE;\")\n",
    "cur.execute(\"CREATE SCHEMA business;\")\n",
    "\n",
    "biz_users = \"\"\"\n",
    "CREATE TABLE business.users (\n",
    "  user_id SERIAL PRIMARY KEY,\n",
    "  username VARCHAR(50) UNIQUE NOT NULL,\n",
    "  password VARCHAR(50) NOT NULL,\n",
    "  age SMALLINT,\n",
    "  created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,\n",
    "  zipcode CHAR(5) DEFAULT NULL REFERENCES census.zipcodes(zipcode) ON DELETE SET NULL\n",
    ");\"\"\"\n",
    "cur.execute(biz_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy over the relevant data from the non-namespaced version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_copy_users = \"\"\"\n",
    "INSERT INTO business.users (username, password, age)\n",
    "SELECT username, password, age FROM users;\"\"\"\n",
    "try:\n",
    "    cur.execute(sql_copy_users)\n",
    "except Exception as err:\n",
    "    conn.rollback()\n",
    "    print(\"Rolling back:\", repr(err), sep='\\n')\n",
    "else:\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,\n",
      " 'Alice',\n",
      " 'bad_pw_1',\n",
      " 37,\n",
      " datetime.datetime(2020, 12, 1, 19, 25, 1, 203001, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=-300, name=None)),\n",
      " None)\n",
      "(2,\n",
      " 'Bob',\n",
      " 'bad_pw_2',\n",
      " None,\n",
      " datetime.datetime(2020, 12, 1, 19, 25, 1, 203001, tzinfo=psycopg2.tz.FixedOffsetTimezone(offset=-300, name=None)),\n",
      " None)\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "cur.execute(\"SELECT * FROM business.users LIMIT 2;\")\n",
    "for row in cur:\n",
    "    pprint(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us test the foreign key constraint we added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolling back:\n",
      "ForeignKeyViolation('insert or update on table \"users\" violates foreign key constraint \"users_zipcode_fkey\"\\nDETAIL:  Key (zipcode)=(ether) is not present in table \"zipcodes\".\\n')\n"
     ]
    }
   ],
   "source": [
    "wanderer = ('Wilma', 'whatever', None, \"ether\")\n",
    "try:\n",
    "    sql = \"\"\"\n",
    "      INSERT INTO business.users (username, password, age, zipcode)\n",
    "      VALUES (%s, %s, %s, %s)\"\"\"\n",
    "    cur.execute(sql, wanderer)\n",
    "except Exception as err:\n",
    "    conn.rollback()\n",
    "    print(\"Rolling back:\", repr(err), sep='\\n')\n",
    "else:\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generated columns\n",
    "![orange-divider](https://user-images.githubusercontent.com/7065401/98619088-44ab6000-22e1-11eb-8f6d-5532e68ab274.png)\n",
    "\n",
    "Suppose we with to emulate initial `census_zipcode_geography` table, but enforce data integrity among columns.  We might define a new table as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_geography = \"\"\"\n",
    "CREATE TABLE census.zipcode_geography (\n",
    "  zipcode CHAR(5) PRIMARY KEY,   -- by implication, UNIQUE NOT NULL\n",
    "  usps VARCHAR GENERATED ALWAYS AS (zipcode) STORED, \n",
    "                              -- actually physically stored for now\n",
    "  aland BIGINT,               -- m^2 \n",
    "  awater BIGINT,\n",
    "  aland_sqmi NUMERIC(8, 3) GENERATED ALWAYS AS (aland / 2589988.1103) STORED, \n",
    "                              -- converted mi^2 from m^2\n",
    "  awater_sqmi NUMERIC(8, 3) GENERATED ALWAYS AS (awater / 2589988.1103) STORED,\n",
    "  intptlat REAL GENERATED ALWAYS AS (location[0]) STORED,\n",
    "  intptlong REAL GENERATED ALWAYS AS (location[1]) STORED,\n",
    "  location POINT              -- use geometric type for lat/lon\n",
    ");\n",
    "\"\"\"\n",
    "cur.execute(sql_geography)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of PostgreSQL 12, generated columns are always generated on write operations and explicitly stored.  In future versions, an option to generate them only on read might become available.  We will see VIEWs in a later lesson, which can accomplish a similar purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us insert an invented data row to demonstrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aland': 25000000,\n",
      " 'aland_sqmi': Decimal('9.653'),\n",
      " 'awater': 10000000,\n",
      " 'awater_sqmi': Decimal('3.861'),\n",
      " 'intptlat': 37.1,\n",
      " 'intptlong': -95.7,\n",
      " 'location': '(37.1,-95.7)',\n",
      " 'usps': '99999',\n",
      " 'zipcode': '99999'}\n"
     ]
    }
   ],
   "source": [
    "sql_99999 = \"\"\"\n",
    "INSERT INTO census.zipcode_geography (zipcode, aland, awater, location)\n",
    "VALUES (99999, 25000000, 10000000, '(37.1, -95.7)')\n",
    "\"\"\"\n",
    "cur.execute(sql_99999)\n",
    "cur.execute(\"SELECT * FROM census.zipcode_geography WHERE zipcode='99999';\")\n",
    "cols = (c.name for c in cur.description)\n",
    "for row in cur:\n",
    "    pprint(dict(zip(cols, row)))\n",
    "\n",
    "# Don't actually keep this data\n",
    "conn.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can copy over the non-generated and non-namespaced data into the new table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_copy_zips = \"\"\"\n",
    "INSERT INTO census.zipcode_geography (zipcode, aland, awater, location)\n",
    "SELECT usps, aland, awater, location FROM census_zipcode_geography;\n",
    "\"\"\"\n",
    "cur.execute(sql_copy_zips)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The census bureau provides the data as both square meters and square miles.  It appears that in 123 of the 33,144 rows, their conversion was not identical to ours.  Whether this matters is a domain judgement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('00685', Decimal('77.532'), Decimal('77.533')),\n",
       " ('03741', Decimal('76.932'), Decimal('76.933')),\n",
       " ('06074', Decimal('28.055'), Decimal('28.056')),\n",
       " ('13656', Decimal('85.074'), Decimal('85.075')),\n",
       " ('14454', Decimal('50.623'), Decimal('50.624')),\n",
       " ('20106', Decimal('60.225'), Decimal('60.226')),\n",
       " ('24018', Decimal('45.385'), Decimal('45.386')),\n",
       " ('24426', Decimal('332.864'), Decimal('332.865')),\n",
       " ('26298', Decimal('11.096'), Decimal('11.097')),\n",
       " ('28504', Decimal('123.768'), Decimal('123.769'))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"\"\"\n",
    "  SELECT new.zipcode, new.aland_sqmi as converted, old.aland_sqmi reported\n",
    "  FROM census_zipcode_geography old\n",
    "  JOIN census.zipcode_geography new\n",
    "  ON (old.usps = new.zipcode)\n",
    "  WHERE new.aland_sqmi != old.aland_sqmi;\"\"\")\n",
    "cur.fetchmany(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Altering tables\n",
    "![orange-divider](https://user-images.githubusercontent.com/7065401/98619088-44ab6000-22e1-11eb-8f6d-5532e68ab274.png)\n",
    "\n",
    "We have copied data from some tables into related tables to refactor the data organization.  We can also change tables in place.  This should be done with caution, since some such alterations will lose information.  In many cases, we can make alterations such as changing to a compatible data type or adding columns, without harming existing data.\n",
    "\n",
    "Recall the simple table that records long descriptions of zipcode field keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('key', 'character varying', 15, None, 'YES'),\n",
       " ('description', 'character varying', None, None, 'YES')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_schema(\"zipcode_fields\", table_schema=\"census\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_fixkey = \"\"\"\n",
    "ALTER TABLE census.zipcode_fields\n",
    "ALTER key TYPE CHAR(20);  -- using fixed length keys\n",
    "\"\"\"\n",
    "cur.execute(sql_fixkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_refcol = \"\"\"\n",
    "ALTER TABLE census.zipcode_fields\n",
    "ADD reference VARCHAR DEFAULT 'https://www.census.gov/data/tables.html';\n",
    "\"\"\"\n",
    "cur.execute(sql_refcol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('USPS                ',\n",
       "  'United States Postal Service State Abbreviation',\n",
       "  'https://www.census.gov/data/tables.html'),\n",
       " ('GEOID               ',\n",
       "  'Geographic Identifier - fully concatenated geographic code (State FIPS and district number)',\n",
       "  'https://www.census.gov/data/tables.html'),\n",
       " ('ALAND               ',\n",
       "  'Land Area (square meters) - Created for statistical purposes only',\n",
       "  'https://www.census.gov/data/tables.html')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute('SELECT * FROM census.zipcode_fields LIMIT 3;')\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "![orange-divider](https://user-images.githubusercontent.com/7065401/98619088-44ab6000-22e1-11eb-8f6d-5532e68ab274.png)\n",
    "\n",
    "We looked here at highlights of the PostgreSQL DDL.  Various other elements of it are shown in other lessons, both before and after this one.\n",
    "\n",
    "In the next lesson we look at data types available for PostgreSQL."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
